# app/routers/stream.py
from __future__ import annotations
import os
import asyncio
import platform
import json
import types
from pathlib import Path
import jwt
import numpy as np
import requests
import cv2, time, threading
from typing import Dict, Tuple
from starlette.concurrency import iterate_in_threadpool
from starlette.responses import StreamingResponse


from fastapi import APIRouter, Query
from app.models.inference import run_inference_on_image, _engine  # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë° ì—”ì§„

_caps: Dict[Tuple[str,int,int], cv2.VideoCapture] = {}
_caps_lock = threading.Lock()
router = APIRouter(prefix="/stream", tags=["stream"])

# ========= ì´ë²¤íŠ¸ ì „ì†¡ =========
EVENT_URL = os.getenv("EVENT_URL", "http://localhost:3002/events")
AI_JWT_SECRET = os.getenv("AI_JWT_SECRET", "changeme")
SESSION = requests.Session()

_AI_JWT = None
_AI_JWT_EXP = 0
_AI_JWT_KEY = None  # (secret, camera_id)ì„ ê¸°ì–µí•´ì„œ í‚¤ê°€ ë°”ë€Œë©´ ì¬ë°œê¸‰
_SENT_STARTED: set[str] = set()
_SENT_IDENTITY: set[str] = set()

def _get_ai_token(camera_id: str = "cam2") -> str:
    """AI ì—­í• ìš© JWTë¥¼ ìºì‹±í•´ì„œ ì‚¬ìš©."""
    global _AI_JWT, _AI_JWT_EXP, _AI_JWT_KEY
    secret = os.getenv("AI_JWT_SECRET", "changeme")
    now = int(time.time())
    key = (secret, camera_id)

    need_new = (
        _AI_JWT is None
        or (_AI_JWT_EXP - 30) <= now
        or _AI_JWT_KEY != key
    )

    if need_new:
        payload = {
            "sub": "ai",
            "role": "ai",           # verifyAIê°€ ì†Œë¬¸ì 'ai' ìš”êµ¬ â†’ í™•ì‹¤íˆ ì†Œë¬¸ìë¡œ
            "camera_id": camera_id,
            "iat": now,
            "exp": now + 60 * 5,    # ìºì‹œ/ê²€ì¦ ë¬¸ì œ ì¤„ì´ë ¤ 5ë¶„ìœ¼ë¡œ ë‹¨ì¶• (ì›í•˜ë©´ 30ë¶„ìœ¼ë¡œ)
        }
        tok = jwt.encode(payload, secret, algorithm="HS256")
        if isinstance(tok, bytes):
            tok = tok.decode("utf-8")
        _AI_JWT = tok
        _AI_JWT_EXP = payload["exp"]
        _AI_JWT_KEY = key

        print(f"[AI_TOKEN] issued role=ai cam={camera_id} exp={_AI_JWT_EXP} secret_fpr={hash(secret)%100000:05d}")

    return _AI_JWT

def _post_event(payload: dict, camera_id: str = "cam0") -> None:
    base = os.getenv("EVENT_SERVER_URL", "http://localhost:3002")
    url = f"{base.rstrip('/')}/events"

    # í† í° ìƒì„±
    now = int(time.time())
    token = jwt.encode(
        {"sub": "ai", "role": "ai", "camera_id": camera_id, "iat": now, "exp": now + 300},
        AI_JWT_SECRET,
        algorithm="HS256",
    )
    if isinstance(token, bytes):
        token = token.decode("utf-8")

    body = dict(payload)
    body.setdefault("camera_id", camera_id)
    body.setdefault("at", now)

    if "event_type" not in body and "type" in body:
        body["event_type"] = str(body.pop("type")).lower()

    # í—¤ë” êµ¬ì„±
    headers = {
        "Authorization": f"Bearer {token}",
        "X-AI-Token": token,
        "Content-Type": "application/json",
    }

    # ğŸ” ë””ë²„ê·¸ìš© ë¡œê·¸ ì¶”ê°€ â€” ì‹¤ì œ ì–´ë–¤ í† í°/URLë¡œ ë³´ë‚´ëŠ”ì§€ í™•ì¸
    print(f"[POST_EVENT] â†’ {url}")
    print(f"[POST_EVENT] headers.Authorization = Bearer {token[:40]}...")  # ì•ë¶€ë¶„ë§Œ
    print(f"[POST_EVENT] payload = {body}")

    try:
        r = SESSION.post(url, json=body, headers=headers, timeout=5)
        if r.status_code == 401:
            print("[POST_EVENT] âš ï¸ 401 Unauthorized â€” retrying without X-AI-Token header...")
            alt_headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
            r = SESSION.post(url, json=body, headers=alt_headers, timeout=5)

        if 200 <= r.status_code < 300:
            print(f"[AIâ†’EVENT] âœ… {r.status_code} {body.get('event_type')}")
        else:
            print(f"[AIâ†’EVENT] âŒ {r.status_code} {r.text[:200]}")
    except Exception as e:
        print(f"[AIâ†’EVENT] EXC {e.__class__.__name__}: {e}")

    try:
        r = SESSION.post(url, json=body, headers=headers, timeout=5)
        if r.status_code == 401:
            # í˜¹ì‹œ Authorizationë§Œ í—ˆìš©/ë¶ˆí—ˆê°€ ì„ì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ 2ì°¨ ì‹œë„
            alt_headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
            r = SESSION.post(url, json=body, headers=alt_headers, timeout=5)

        if 200 <= r.status_code < 300:
            print(f"[AIâ†’EVENT] {r.status_code} {body.get('type')}")
        else:
            print(f"[AIâ†’EVENT] {r.status_code} {r.text[:200]}")
    except Exception as e:
        print(f"[AIâ†’EVENT] EXC {e.__class__.__name__}: {e}")

def _safe_int_pair(t):
    # ('12','34') ê°™ì€ ë¬¸ìì—´ ì¢Œí‘œë„ ì•ˆì „íˆ ë³€í™˜
    return (int(float(t[0])), int(float(t[1])))


def draw_seats(frame: np.ndarray, show_debug: bool = True, style: str = "core") -> np.ndarray:
    h, w = frame.shape[:2]
    seats = _engine().get_seats() or []

    # 0) ì¢Œí‘œ ìŠ¤ì¼€ì¼ ê²°ì • (ì •ê·œí™”/ê¸°ì¤€í•´ìƒë„ ìë™ ì¶”ì •)
    xs, ys = [], []
    for s in seats:
        p1 = s.get("p1") if isinstance(s, dict) else list(getattr(s, "p1"))
        p2 = s.get("p2") if isinstance(s, dict) else list(getattr(s, "p2"))
        xs += [float(p1[0]), float(p2[0])]
        ys += [float(p1[1]), float(p2[1])]

    xmax, ymax = (max(xs or [0.0]), max(ys or [0.0]))
    normalized = (xmax <= 1.01 and ymax <= 1.01)
    if normalized:
        scale_x, scale_y = float(w), float(h)
    else:
        # í”½ì…€ ì¢Œí‘œ: ì¢Œì„ ì •ì˜ ë‹¹ì‹œì˜ ê¸°ì¤€ í•´ìƒë„ ì¶”ì • â†’ í”„ë ˆì„ë³´ë‹¤ í° ê°’ì´ë©´ ê·¸ê±¸ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼
        base_w = max(float(xmax), float(w)) or 1.0
        base_h = max(float(ymax), float(h)) or 1.0
        scale_x = w / base_w if xmax > w * 1.02 else 1.0
        scale_y = h / base_h if ymax > h * 1.02 else 1.0

    if show_debug:
        cv2.putText(frame, f"{w}x{h}  seats:{len(seats)}",
                    (14, 36), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)

    if not seats:
        return frame

    for s in seats:
        # ì•ˆì „ ì¶”ì¶œ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
        if isinstance(s, dict):
            p1 = s.get("p1", [0, 0]); p2 = s.get("p2", [0, 0])
            d_near = float(s.get("d_near", 0)); d_far = float(s.get("d_far", 0))
            inward = 1 if int(s.get("inward_sign", 1)) >= 0 else -1
            seat_id = int(s.get("seat_id", 0))
            ref_w = int(s.get("ref_w", w)); ref_h = int(s.get("ref_h", h))  # ì°¸ì¡° í•´ìƒë„
        else:
            p1 = list(getattr(s, "p1")); p2 = list(getattr(s, "p2"))
            d_near = float(getattr(s, "d_near")); d_far = float(getattr(s, "d_far"))
            inward = 1 if int(getattr(s, "inward_sign")) >= 0 else -1
            seat_id = int(getattr(s, "seat_id", 0))
            # SeatWire ê°ì²´ì—ì„œ ì°¸ì¡° í•´ìƒë„ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ í˜„ì¬ í”„ë ˆì„ í•´ìƒë„ë¥¼ ê°€ì •)
            ref_w = int(getattr(s, "ref_w", w))
            ref_h = int(getattr(s, "ref_h", h))

        # 1) ì—¬ê¸°ë§Œ ë³€ê²½: ì¢Œí‘œ ìŠ¤ì¼€ì¼ ì ìš©
        x1, y1 = float(p1[0]) * scale_x, float(p1[1]) * scale_y
        x2, y2 = float(p2[0]) * scale_x, float(p2[1]) * scale_y

        # 2) ì´í•˜ ê¸°ì¡´ ë¡œì§ ë™ì¼
        ux, uy = (x2 - x1), (y2 - y1)
        L = (ux*ux + uy*uy) ** 0.5
        if L < 1e-6:
            continue
        nx = inward * (-uy / L)
        ny = inward * ( ux / L)

        y_near = max(y1, y2)
        y_far  = min(y1, y2)
        if abs(y_near - y_far) < 1e-6:
            d1 = d2 = d_near
        else:
            def depth_at(y):
                t = (y - y_far) / (y_near - y_far)
                t = 0.0 if t < 0 else (1.0 if t > 1 else t)
                return d_far * (1.0 - t) + d_near * t
            d1, d2 = depth_at(y1), depth_at(y2)

        a2 = (int(x1 + nx * d1), int(y1 + ny * d1))
        b2 = (int(x2 + nx * d2), int(y2 + ny * d2))
        poly = np.array([(int(x1), int(y1)), (int(x2), int(y2)), b2, a2], dtype=np.int32)

        cv2.polylines(frame, [poly], True, (0, 255, 255), 2, cv2.LINE_AA)
        if style == "config":
            # ì¶”ê°€: band ê°€ì´ë“œë¥¼ configì™€ ê°™ì€ ë£©ìœ¼ë¡œ í‘œì‹œ(b_near/b_far ë³´ê°„)
            # y1,y2ì— ëŒ€í•´ band ê°’ì„ ë³´ê°„í•´ì„œ Â±bandë§Œí¼ í‰í–‰ì´ë™í•œ "ì–‡ì€ í´ë¦¬ë¼ì¸"ì„ ë§ê·¸ë¦½ë‹ˆë‹¤.
            # (seat dict/ê°ì²´ì—ì„œ b_near,b_far ì•ˆì „ ì¶”ì¶œ)
            b_near = float(s.get("b_near", 20.0)) if isinstance(s, dict) else float(getattr(s, "b_near", 20.0))
            b_far  = float(s.get("b_far", 8.0))   if isinstance(s, dict) else float(getattr(s, "b_far", 8.0))

            def band_at(y):
                # stream.py ì½”ì–´ì¡´ ê¹Šì´ ë³´ê°„ê³¼ ë™ì¼í•œ t ì‚¬ìš©  # å‚ç…§: :contentReference[oaicite:10]{index=10}
                t = (y - y_far) / (y_near - y_far) if abs(y_near - y_far) > 1e-6 else 0.0
                t = 0.0 if t < 0 else (1.0 if t > 1 else t)
                return b_far * (1.0 - t) + b_near * t

            # p1, p2ì—ì„œì˜ band ê³„ì‚°
            band1, band2 = band_at(y1), band_at(y2)

            # ë°´ë“œ ë¼ì¸(ì½”ì–´ ë°”ê¹¥ìª½ ë˜ëŠ” ì•ˆìª½)ì— ì–‡ì€ í´ë¦¬ë¼ì¸ ì¶”ê°€(ìƒ‰/ë‘ê»˜ëŠ” ì·¨í–¥)
            a_band = (int(x1 + nx * (d1 + band1)), int(y1 + ny * (d1 + band1)))
            b_band = (int(x2 + nx * (d2 + band2)), int(y2 + ny * (d2 + band2)))
            band_poly = np.array([(int(x1), int(y1)), (int(x2), int(y2)), b_band, a_band], dtype=np.int32)
            cv2.polylines(frame, [band_poly], True, (0, 200, 255), 1, cv2.LINE_AA)  # ì‚´ì§ ë‹¤ë¥¸ í†¤
            
        midx = int((x1 + x2) * 0.5 + nx * (d1 + 12))
        midy = int((y1 + y2) * 0.5 + ny * (d1 + 12))
        cv2.putText(frame, f"Seat {seat_id}", (midx, midy),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (230, 230, 230), 2, cv2.LINE_AA)

    return frame


# ========= ì¹´ë©”ë¼ =========
def _open_cap(src: str, width: int = 1280, height: int = 960) -> cv2.VideoCapture:
    """Windowsì—ì„œ ë°±ì—”ë“œ ë°±ì—… + ì¬ì‹œë„ + ì›Œë°ì—…ê¹Œì§€ í¬í•¨í•´ì„œ ì•ˆì •ì ìœ¼ë¡œ ì—°ë‹¤."""
    # í‚¤: (src,width,height)ë³„ë¡œ í•œ ë²ˆë§Œ ì˜¤í”ˆ
    key = (src, width, height)
    with _caps_lock:
        if key in _caps and _caps[key].isOpened():
            return _caps[key]

        # ìƒˆë¡œ ì‹œë„
        def _try_open(backend=None):
            if src.strip().isdigit():
                idx = int(src)
                cap = cv2.VideoCapture(idx, backend) if backend is not None else cv2.VideoCapture(idx)
            else:
                cap = cv2.VideoCapture(src)
            if not cap or not cap.isOpened():
                return None
            # í•´ìƒë„/ì½”ë±/FPS ì„¤ì •
            cap.set(cv2.CAP_PROP_FRAME_WIDTH,  width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            # ì¼ë¶€ ì¥ì¹˜ì—ì„œ MJPGë¡œ ë°”ê¿”ì•¼ í•´ìƒë„/í”„ë ˆì„ì´ ì•ˆì •
            cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*"MJPG"))
            cap.set(cv2.CAP_PROP_FPS, 30)
            # MSMFì—ì„œ ë²„í¼ ì¤„ì´ë©´ ì§€ì—° ì¤„ì–´ë“¦(ì§€ì› ì•ˆ í•˜ë©´ ë¬´ì‹œ)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            # ì›Œë°ì—…: ì´ˆê¸° í”„ë ˆì„ ë²„ë¦¬ê¸°
            for _ in range(8):
                cap.read()
                time.sleep(0.01)
            return cap

        # ë°±ì—”ë“œ ìš°ì„ ìˆœìœ„: DSHOW â†’ MSMF â†’ ê¸°ë³¸
        backends = [cv2.CAP_DSHOW, cv2.CAP_MSMF, None]
        last_err = None
        for be in backends:
            cap = _try_open(be)
            if cap and cap.isOpened():
                _caps[key] = cap
                return cap
            last_err = be

        raise RuntimeError(f"Failed to open camera src={src} backend_tried={last_err}")

def _close_cap_if_unused(src: str, width: int, height: int):
    key = (src, width, height)
    with _caps_lock:
        cap = _caps.pop(key, None)
        if cap is not None:
            try:
                cap.release()
            except Exception:
                pass


# ========= ìŠ¤íŠ¸ë¦¬ë° =========
def mjpeg_generator(
    source: str,
    do_blur: bool,
    do_intrusion: bool,
    scale: float,
    quality: int,
    conf: float | None,
    roi_debug: bool,
    width: int = 1280,
    height: int = 960,
):
    cap = _open_cap(source, width=width, height=height)

    # ì—°ì† ì‹¤íŒ¨ ì¹´ìš´í„°
    fail_cnt = 0
    FAIL_REOPEN = 10  # ì—°ì† 10í”„ë ˆì„ ì‹¤íŒ¨í•˜ë©´ ì¬ì˜¤í”ˆ

    try:
        while True:
            try:
                ok, frame = cap.read()
                if not ok or frame is None:
                    fail_cnt += 1
                    if fail_cnt >= FAIL_REOPEN:
                        print("[stream] read() consecutive fail -> reopen camera")
                        try:
                            cap.release()
                        except Exception:
                            pass
                        time.sleep(0.2)
                        cap = _open_cap(source, width=width, height=height)
                        fail_cnt = 0
                    else:
                        time.sleep(0.02)
                    continue

                # ì •ìƒ ì½ê¸°
                fail_cnt = 0

                # 1) ì¶”ë¡  (ë¸”ëŸ¬/ì¹¨ì…)
                cam_id = f"cam{source}" if str(source).strip().isdigit() else str(source)
                try:
                    res = run_inference_on_image(
                        frame,
                        camera_id=cam_id,
                        do_blur=do_blur,
                        do_intrusion=do_intrusion,
                    )
                except Exception as e:
                    print("[stream] run_inference_on_image() failed:", e)
                    res = types.SimpleNamespace()
                    res.frame = frame                      # â† ì—¬ê¸°ì„œ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€ì…
                    res.intrusion_started = False
                    res.intrusion_active = False
                    res.seat_id = None
                    res.meta = {"camera_id": cam_id}
                    res.identity = None
                    res.identity_conf = None
                    res.phone_capture = None

                # 2) ROI ì˜¤ë²„ë ˆì´
                if roi_debug:
                    frame = draw_seats(frame, show_debug=True, style="config")

                # 3) ì´ë²¤íŠ¸ ì „ì†¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                cid = (res.meta or {}).get("correlation_id")

                if (not res.intrusion_active) and cid:
                    _SENT_STARTED.discard(cid)
                    _SENT_IDENTITY.discard(cid)

            except Exception as e:
                # OpenCV/ì¶”ë¡  ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ: ë¡œê·¸ + ì¬ì˜¤í”ˆ + ì•ˆì „ í”„ë ˆì„
                print("[stream] inner error:", repr(e))
                try:
                    cap.release()
                except Exception:
                    pass
                time.sleep(0.5)
                cap = _open_cap(source, width=width, height=height)

                if 'frame' in locals() and frame is not None:
                    overlay = frame.copy()
                else:
                    overlay = np.zeros((height, width, 3), dtype=np.uint8)

                h_, w_ = overlay.shape[:2]
                cv2.rectangle(overlay, (0, 0), (w_, 40), (0, 0, 255), -1)
                cv2.putText(overlay, f"inference error: {str(e)[:60]}",
                            (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                frame = overlay

            # 4) ë¦¬ì‚¬ì´ì¦ˆ & JPEG ì¸ì½”ë”©
            if scale != 1.0:
                h0, w0 = frame.shape[:2]
                frame = cv2.resize(frame, (int(w0 * scale), int(h0 * scale)), interpolation=cv2.INTER_LINEAR)

            ok, jpg = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)])
            if not ok:
                continue

            yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n"
                   + jpg.tobytes() + b"\r\n")
            del jpg
            time.sleep(0.03)  # ~30fps
    finally:
        try:
            cap.release()
        except Exception:
            pass



# ========= ë¼ìš°íŠ¸ =========
@router.get("/raw")
def stream_raw(
    cam: str = "0",
    scale: float = Query(1.0, ge=0.25, le=2.0),
    quality: int = Query(80, ge=10, le=95),
    roi: int = Query(1, description="ì¢Œì„ ì‹œê°í™”(1=on, 0=off)"),
    w: int = Query(1280),
    h: int = Query(960),
):
    async def _stream():
        try:
            async for chunk in iterate_in_threadpool(
                mjpeg_generator(
                    source=cam,
                    do_blur=False,
                    do_intrusion=False,
                    scale=scale,
                    quality=quality,
                    conf=None,
                    roi_debug=bool(roi),
                    width=w,
                    height=h,
                )
            ):
                yield chunk
        except (GeneratorExit, asyncio.CancelledError):
            # íƒ­ ë‹«í˜ ë“± ì •ìƒ ì¢…ë£Œ
            pass
        except Exception as e:
            print("[stream/raw] outer error:", repr(e))

    return StreamingResponse(_stream(), media_type="multipart/x-mixed-replace; boundary=frame")

@router.get("/blur")
def stream_blur(
    cam: str = "0",
    conf: float | None = Query(None, description="override model confidence (0~1)"),
    scale: float = Query(1.0, ge=0.25, le=2.0),
    quality: int = Query(80, ge=10, le=95),
    roi: int = Query(1, description="ì¢Œì„ ì‹œê°í™”(1=on, 0=off)"),
    w: int = Query(1280, description="ì¶œë ¥ ê°€ë¡œ í•´ìƒë„"),
    h: int = Query(960, description="ì¶œë ¥ ì„¸ë¡œ í•´ìƒë„"),
):
    async def _stream():
        try:
            async for chunk in iterate_in_threadpool(
                mjpeg_generator(
                    source=cam,
                    do_blur=True,
                    do_intrusion=True,
                    scale=scale,
                    quality=quality,
                    conf=conf,
                    roi_debug=bool(roi),
                    width=w,
                    height=h,
                )
            ):
                yield chunk
        except (GeneratorExit, asyncio.CancelledError):
            # íƒ­ ë‹«í˜ ë“± ì •ìƒ ì¢…ë£Œ
            pass
        except Exception as e:
            print("[stream/raw] outer error:", repr(e))

    return StreamingResponse(_stream(), media_type="multipart/x-mixed-replace; boundary=frame")