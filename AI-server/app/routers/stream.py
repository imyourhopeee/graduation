# app/routers/stream.py
from __future__ import annotations
import os
import asyncio
import platform
import json
import types
from pathlib import Path
import jwt
import numpy as np
import requests
import cv2, time, threading
from typing import Dict, Tuple
from starlette.concurrency import iterate_in_threadpool
from starlette.responses import StreamingResponse


from fastapi import APIRouter, Query
from app.models.inference import run_inference_on_image, _engine  # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë° ì—”ì§„

_caps: Dict[Tuple[str,int,int], cv2.VideoCapture] = {}
_caps_lock = threading.Lock()
router = APIRouter(prefix="/stream", tags=["stream"])

# ========= ì´ë²¤íŠ¸ ì „ì†¡ =========
EVENT_URL = os.getenv("EVENT_URL", "http://localhost:3002/events")
AI_JWT_SECRET = os.getenv("AI_JWT_SECRET", "changeme")
SESSION = requests.Session()

_AI_JWT = None
_AI_JWT_EXP = 0
_AI_JWT_KEY = None  # (secret, camera_id)ì„ ê¸°ì–µí•´ì„œ í‚¤ê°€ ë°”ë€Œë©´ ì¬ë°œê¸‰
_SENT_STARTED: set[str] = set()
_SENT_IDENTITY: set[str] = set()

def _get_ai_token(camera_id: str = "cam2") -> str:
    """AI ì—­í• ìš© JWTë¥¼ ìºì‹±í•´ì„œ ì‚¬ìš©."""
    global _AI_JWT, _AI_JWT_EXP, _AI_JWT_KEY
    secret = os.getenv("AI_JWT_SECRET", "changeme")
    now = int(time.time())
    key = (secret, camera_id)

    need_new = (
        _AI_JWT is None
        or (_AI_JWT_EXP - 30) <= now
        or _AI_JWT_KEY != key
    )

    if need_new:
        payload = {
            "sub": "ai",
            "role": "ai",           # verifyAIê°€ ì†Œë¬¸ì 'ai' ìš”êµ¬ â†’ í™•ì‹¤íˆ ì†Œë¬¸ìë¡œ
            "camera_id": camera_id,
            "iat": now,
            "exp": now + 60 * 5,    # ìºì‹œ/ê²€ì¦ ë¬¸ì œ ì¤„ì´ë ¤ 5ë¶„ìœ¼ë¡œ ë‹¨ì¶• (ì›í•˜ë©´ 30ë¶„ìœ¼ë¡œ)
        }
        tok = jwt.encode(payload, secret, algorithm="HS256")
        if isinstance(tok, bytes):
            tok = tok.decode("utf-8")
        _AI_JWT = tok
        _AI_JWT_EXP = payload["exp"]
        _AI_JWT_KEY = key

        print(f"[AI_TOKEN] issued role=ai cam={camera_id} exp={_AI_JWT_EXP} secret_fpr={hash(secret)%100000:05d}")

    return _AI_JWT

    # # í† í°ì´ ì—†ê±°ë‚˜ ë§Œë£Œ ì„ë°•(30ì´ˆ ì´ë‚´)ì´ë©´ ì¬ë°œê¸‰
    # if (not _AI_JWT) or (now > (_AI_JWT_EXP - 30)):
    #     payload = {
    #         "sub": "ai",
    #         "role": "ai",
    #         "camera_id": camera_id,
    #         "iat": now,
    #         "exp": now + 60 * 30,  # 30ë¶„ ìœ íš¨ (ì£¼ì„ì€ 10ë¶„ì´ì—ˆëŠ”ë° ì‹¤ì œê°’ê³¼ ë§ì¶¤)
    #     }
    #     tok = jwt.encode(payload, AI_JWT_SECRET, algorithm="HS256")
    #     if isinstance(tok, bytes):  # PyJWT v1 ëŒ€ë¹„
    #         tok = tok.decode("utf-8")
    #     _AI_JWT = tok
    #     _AI_JWT_EXP = payload["exp"]

    # return _AI_JWT

def _post_event(payload: dict, camera_id: str = "cam0") -> None:
    base = os.getenv("EVENT_SERVER_URL", "http://localhost:3002")
    url = f"{base.rstrip('/')}/events"

    # í† í° ìƒì„±
    now = int(time.time())
    token = jwt.encode(
        {"sub": "ai", "role": "ai", "camera_id": camera_id, "iat": now, "exp": now + 300},
        AI_JWT_SECRET,
        algorithm="HS256",
    )
    if isinstance(token, bytes):
        token = token.decode("utf-8")

    body = dict(payload)
    body.setdefault("camera_id", camera_id)
    body.setdefault("at", now)

    # í—¤ë” êµ¬ì„±
    headers = {
        "Authorization": f"Bearer {token}",
        "X-AI-Token": token,
        "Content-Type": "application/json",
    }

    # ğŸ” ë””ë²„ê·¸ìš© ë¡œê·¸ ì¶”ê°€ â€” ì‹¤ì œ ì–´ë–¤ í† í°/URLë¡œ ë³´ë‚´ëŠ”ì§€ í™•ì¸
    print(f"[POST_EVENT] â†’ {url}")
    print(f"[POST_EVENT] headers.Authorization = Bearer {token[:40]}...")  # ì•ë¶€ë¶„ë§Œ
    print(f"[POST_EVENT] payload = {body}")

    try:
        r = SESSION.post(url, json=body, headers=headers, timeout=5)
        if r.status_code == 401:
            print("[POST_EVENT] âš ï¸ 401 Unauthorized â€” retrying without X-AI-Token header...")
            alt_headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
            r = SESSION.post(url, json=body, headers=alt_headers, timeout=5)

        if 200 <= r.status_code < 300:
            print(f"[AIâ†’EVENT] âœ… {r.status_code} {body.get('type')}")
        else:
            print(f"[AIâ†’EVENT] âŒ {r.status_code} {r.text[:200]}")
    except Exception as e:
        print(f"[AIâ†’EVENT] EXC {e.__class__.__name__}: {e}")

# def _post_event(payload: dict, camera_id: str = "cam0") -> None:
#     # .env í‚¤ë¥¼ ë„ˆí¬ ì´ë²¤íŠ¸ ì„œë²„ ëª…ì„¸ì— ë§ì¶¤ (EVENT_SERVER_URL ì‚¬ìš©)
#     base = os.getenv("EVENT_SERVER_URL", "http://localhost:3002")
#     url = f"{base.rstrip('/')}/events"

#     # í† í°ì€ HS256, role=ai, camera_id í¬í•¨
#     now = int(time.time())
#     token = jwt.encode(
#         {"role": "ai", "camera_id": camera_id, "iat": now, "exp": now + 300},
#         AI_JWT_SECRET,
#         algorithm="HS256",
#     )
#     if isinstance(token, bytes):
#         token = token.decode("utf-8")

#     body = dict(payload)
#     body.setdefault("camera_id", camera_id)
#     body.setdefault("at", now)

#     # ì—¬ëŸ¬ ì„œë²„ êµ¬í˜„ì„ ëª¨ë‘ ë§Œì¡±ì‹œí‚¤ë„ë¡ ì¸ì¦ì„ ë„‰ë„‰í•˜ê²Œ ë„£ìŒ
#     headers = {
#         "Authorization": f"Bearer {token}",
#         "X-AI-Token": token,                 # ë¯¸ë“¤ì›¨ì–´ê°€ ì´ í—¤ë”ë¥¼ ë³´ëŠ” ê²½ìš° ëŒ€ë¹„
#         "Content-Type": "application/json",
#     }

    try:
        r = SESSION.post(url, json=body, headers=headers, timeout=5)
        if r.status_code == 401:
            # í˜¹ì‹œ Authorizationë§Œ í—ˆìš©/ë¶ˆí—ˆê°€ ì„ì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ 2ì°¨ ì‹œë„
            alt_headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
            r = SESSION.post(url, json=body, headers=alt_headers, timeout=5)

        if 200 <= r.status_code < 300:
            print(f"[AIâ†’EVENT] {r.status_code} {body.get('type')}")
        else:
            print(f"[AIâ†’EVENT] {r.status_code} {r.text[:200]}")
    except Exception as e:
        print(f"[AIâ†’EVENT] EXC {e.__class__.__name__}: {e}")


# def _post_event(payload: dict, camera_id: str = "cam2") -> None:
#     global _AI_JWT, _AI_JWT_EXP
#     try:
#         tok = _get_ai_token(camera_id)
#         headers = {"Authorization": f"Bearer {tok}"}
#         body = dict(payload)
#         body.setdefault("camera_id", camera_id)
#         if "at" not in body and "timestamp" not in body:
#             body["at"] = int(time.time())

#         # 1ì°¨ ìš”ì²­
#         r = SESSION.post(EVENT_URL, json=body, headers=headers, timeout=2.0)

#         # í† í° ë§Œë£Œ ì‹œ 1íšŒë§Œ ì¬ì‹œë„
#         if r.status_code == 401:
#             _AI_JWT = None
#             _AI_JWT_EXP = 0
#             tok = _get_ai_token(camera_id)
#             headers["Authorization"] = f"Bearer {tok}"
#             r = SESSION.post(EVENT_URL, json=body, headers=headers, timeout=2.0)

#         # ìƒíƒœë³„ ë¡œê·¸
#         if 200 <= r.status_code < 300:
#             print(f"[AIâ†’EVENT] âœ… {r.status_code} {payload.get('type')}")
#         elif 400 <= r.status_code < 500:
#             print(f"[AIâ†’EVENT] âš ï¸ Client {r.status_code}")
#         else:
#             print(f"[AIâ†’EVENT] âš ï¸ Server {r.status_code}")

#     except Exception as e:
#         print(f"[AIâ†’EVENT] âŒ Exception: {e.__class__.__name__} {e}")



def _safe_int_pair(t):
    # ('12','34') ê°™ì€ ë¬¸ìì—´ ì¢Œí‘œë„ ì•ˆì „íˆ ë³€í™˜
    return (int(float(t[0])), int(float(t[1])))


def draw_seats(frame: np.ndarray, show_debug: bool = True) -> np.ndarray:
    h, w = frame.shape[:2]
    seats = _engine().get_seats() or []

    # 0) ì¢Œí‘œ ìŠ¤ì¼€ì¼ ê²°ì • (ì •ê·œí™”/ê¸°ì¤€í•´ìƒë„ ìë™ ì¶”ì •)
    xs, ys = [], []
    for s in seats:
        p1 = s.get("p1") if isinstance(s, dict) else list(getattr(s, "p1"))
        p2 = s.get("p2") if isinstance(s, dict) else list(getattr(s, "p2"))
        xs += [float(p1[0]), float(p2[0])]
        ys += [float(p1[1]), float(p2[1])]

    xmax, ymax = (max(xs or [0.0]), max(ys or [0.0]))
    normalized = (xmax <= 1.01 and ymax <= 1.01)
    if normalized:
        scale_x, scale_y = float(w), float(h)
    else:
        # í”½ì…€ ì¢Œí‘œ: ì¢Œì„ ì •ì˜ ë‹¹ì‹œì˜ ê¸°ì¤€ í•´ìƒë„ ì¶”ì • â†’ í”„ë ˆì„ë³´ë‹¤ í° ê°’ì´ë©´ ê·¸ê±¸ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼
        base_w = max(float(xmax), float(w)) or 1.0
        base_h = max(float(ymax), float(h)) or 1.0
        scale_x = w / base_w if xmax > w * 1.02 else 1.0
        scale_y = h / base_h if ymax > h * 1.02 else 1.0

    if show_debug:
        cv2.putText(frame, f"{w}x{h}  seats:{len(seats)}",
                    (14, 36), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)

    if not seats:
        return frame

    for s in seats:
        # ì•ˆì „ ì¶”ì¶œ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
        if isinstance(s, dict):
            p1 = s.get("p1", [0, 0]); p2 = s.get("p2", [0, 0])
            d_near = float(s.get("d_near", 0)); d_far = float(s.get("d_far", 0))
            inward = 1 if int(s.get("inward_sign", 1)) >= 0 else -1
            seat_id = int(s.get("seat_id", 0))
            ref_w = int(s.get("ref_w", w)); ref_h = int(s.get("ref_h", h))  # ì°¸ì¡° í•´ìƒë„
        else:
            p1 = list(getattr(s, "p1")); p2 = list(getattr(s, "p2"))
            d_near = float(getattr(s, "d_near")); d_far = float(getattr(s, "d_far"))
            inward = 1 if int(getattr(s, "inward_sign")) >= 0 else -1
            seat_id = int(getattr(s, "seat_id", 0))
            # SeatWire ê°ì²´ì—ì„œ ì°¸ì¡° í•´ìƒë„ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ í˜„ì¬ í”„ë ˆì„ í•´ìƒë„ë¥¼ ê°€ì •)
            ref_w = int(getattr(s, "ref_w", w))
            ref_h = int(getattr(s, "ref_h", h))

        # 1) ì—¬ê¸°ë§Œ ë³€ê²½: ì¢Œí‘œ ìŠ¤ì¼€ì¼ ì ìš©
        x1, y1 = float(p1[0]) * scale_x, float(p1[1]) * scale_y
        x2, y2 = float(p2[0]) * scale_x, float(p2[1]) * scale_y

        # 2) ì´í•˜ ê¸°ì¡´ ë¡œì§ ë™ì¼
        ux, uy = (x2 - x1), (y2 - y1)
        L = (ux*ux + uy*uy) ** 0.5
        if L < 1e-6:
            continue
        nx = inward * (-uy / L)
        ny = inward * ( ux / L)

        y_near = max(y1, y2)
        y_far  = min(y1, y2)
        if abs(y_near - y_far) < 1e-6:
            d1 = d2 = d_near
        else:
            def depth_at(y):
                t = (y - y_far) / (y_near - y_far)
                t = 0.0 if t < 0 else (1.0 if t > 1 else t)
                return d_far * (1.0 - t) + d_near * t
            d1, d2 = depth_at(y1), depth_at(y2)

        a2 = (int(x1 + nx * d1), int(y1 + ny * d1))
        b2 = (int(x2 + nx * d2), int(y2 + ny * d2))
        poly = np.array([(int(x1), int(y1)), (int(x2), int(y2)), b2, a2], dtype=np.int32)

        cv2.polylines(frame, [poly], True, (0, 255, 255), 2, cv2.LINE_AA)

        midx = int((x1 + x2) * 0.5 + nx * (d1 + 12))
        midy = int((y1 + y2) * 0.5 + ny * (d1 + 12))
        cv2.putText(frame, f"Seat {seat_id}", (midx, midy),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (230, 230, 230), 2, cv2.LINE_AA)

    return frame


# ========= ì¹´ë©”ë¼ =========
def _open_cap(src: str, width: int = 1280, height: int = 960) -> cv2.VideoCapture:
    """Windowsì—ì„œ ë°±ì—”ë“œ ë°±ì—… + ì¬ì‹œë„ + ì›Œë°ì—…ê¹Œì§€ í¬í•¨í•´ì„œ ì•ˆì •ì ìœ¼ë¡œ ì—°ë‹¤."""
    # í‚¤: (src,width,height)ë³„ë¡œ í•œ ë²ˆë§Œ ì˜¤í”ˆ
    key = (src, width, height)
    with _caps_lock:
        if key in _caps and _caps[key].isOpened():
            return _caps[key]

        # ìƒˆë¡œ ì‹œë„
        def _try_open(backend=None):
            if src.strip().isdigit():
                idx = int(src)
                cap = cv2.VideoCapture(idx, backend) if backend is not None else cv2.VideoCapture(idx)
            else:
                cap = cv2.VideoCapture(src)
            if not cap or not cap.isOpened():
                return None
            # í•´ìƒë„/ì½”ë±/FPS ì„¤ì •
            cap.set(cv2.CAP_PROP_FRAME_WIDTH,  width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            # ì¼ë¶€ ì¥ì¹˜ì—ì„œ MJPGë¡œ ë°”ê¿”ì•¼ í•´ìƒë„/í”„ë ˆì„ì´ ì•ˆì •
            cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*"MJPG"))
            cap.set(cv2.CAP_PROP_FPS, 30)
            # MSMFì—ì„œ ë²„í¼ ì¤„ì´ë©´ ì§€ì—° ì¤„ì–´ë“¦(ì§€ì› ì•ˆ í•˜ë©´ ë¬´ì‹œ)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            # ì›Œë°ì—…: ì´ˆê¸° í”„ë ˆì„ ë²„ë¦¬ê¸°
            for _ in range(8):
                cap.read()
                time.sleep(0.01)
            return cap

        # ë°±ì—”ë“œ ìš°ì„ ìˆœìœ„: DSHOW â†’ MSMF â†’ ê¸°ë³¸
        backends = [cv2.CAP_DSHOW, cv2.CAP_MSMF, None]
        last_err = None
        for be in backends:
            cap = _try_open(be)
            if cap and cap.isOpened():
                _caps[key] = cap
                return cap
            last_err = be

        raise RuntimeError(f"Failed to open camera src={src} backend_tried={last_err}")

def _close_cap_if_unused(src: str, width: int, height: int):
    key = (src, width, height)
    with _caps_lock:
        cap = _caps.pop(key, None)
        if cap is not None:
            try:
                cap.release()
            except Exception:
                pass


# ========= ìŠ¤íŠ¸ë¦¬ë° =========
def mjpeg_generator(
    source: str,
    do_blur: bool,
    do_intrusion: bool,
    scale: float,
    quality: int,
    conf: float | None,
    roi_debug: bool,
    width: int = 1280,
    height: int = 960,
):
    cap = _open_cap(source, width=width, height=height)

    # ì—°ì† ì‹¤íŒ¨ ì¹´ìš´í„°
    fail_cnt = 0
    FAIL_REOPEN = 10  # ì—°ì† 10í”„ë ˆì„ ì‹¤íŒ¨í•˜ë©´ ì¬ì˜¤í”ˆ

    try:
        while True:
            try:
                ok, frame = cap.read()
                if not ok or frame is None:
                    fail_cnt += 1
                    if fail_cnt >= FAIL_REOPEN:
                        print("[stream] read() consecutive fail -> reopen camera")
                        try:
                            cap.release()
                        except Exception:
                            pass
                        time.sleep(0.2)
                        cap = _open_cap(source, width=width, height=height)
                        fail_cnt = 0
                    else:
                        time.sleep(0.02)
                    continue

                # ì •ìƒ ì½ê¸°
                fail_cnt = 0

                # 1) ì¶”ë¡  (ë¸”ëŸ¬/ì¹¨ì…)
                cam_id = f"cam{source}" if str(source).strip().isdigit() else str(source)
                try:
                    res = run_inference_on_image(
                        frame,
                        camera_id=cam_id,
                        do_blur=do_blur,
                        do_intrusion=do_intrusion,
                    )
                except Exception as e:
                    print("[stream] run_inference_on_image() failed:", e)
                    res = types.SimpleNamespace()
                    res.frame = frame                      # â† ì—¬ê¸°ì„œ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€ì…
                    res.intrusion_started = False
                    res.intrusion_active = False
                    res.seat_id = None
                    res.meta = {"camera_id": cam_id}
                    res.identity = None
                    res.identity_conf = None
                    res.phone_capture = None

                # 2) ROI ì˜¤ë²„ë ˆì´
                if roi_debug:
                    frame = draw_seats(frame, show_debug=True)

                # 3) ì´ë²¤íŠ¸ ì „ì†¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                cid = (res.meta or {}).get("correlation_id")
                if res.intrusion_started and cid and cid not in _SENT_STARTED:
                    _post_event({
                        "type": "intrusion_started",
                        "correlation_id": cid,
                        "seat_id": res.seat_id,
                        "camera_id": (res.meta or {}).get("camera_id"),
                        "identity": res.identity,
                        "identity_conf": res.identity_conf,
                        "phone_capture": res.phone_capture,
                        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    })
                    _SENT_STARTED.add(cid)

                if res.intrusion_active and cid and (res.identity is not None) and (cid not in _SENT_IDENTITY):
                    _post_event({
                        "type": "intrusion_identity",
                        "correlation_id": cid,
                        "seat_id": res.seat_id,
                        "camera_id": (res.meta or {}).get("camera_id"),
                        "identity": res.identity,
                        "identity_conf": res.identity_conf,
                        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    })
                    _SENT_IDENTITY.add(cid) #ì¤‘ë³µë°©ì§€

                if (not res.intrusion_active) and cid:
                    _SENT_STARTED.discard(cid)
                    _SENT_IDENTITY.discard(cid)

            except Exception as e:
                # OpenCV/ì¶”ë¡  ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ: ë¡œê·¸ + ì¬ì˜¤í”ˆ + ì•ˆì „ í”„ë ˆì„
                print("[stream] inner error:", repr(e))
                try:
                    cap.release()
                except Exception:
                    pass
                time.sleep(0.5)
                cap = _open_cap(source, width=width, height=height)

                if 'frame' in locals() and frame is not None:
                    overlay = frame.copy()
                else:
                    overlay = np.zeros((height, width, 3), dtype=np.uint8)

                h_, w_ = overlay.shape[:2]
                cv2.rectangle(overlay, (0, 0), (w_, 40), (0, 0, 255), -1)
                cv2.putText(overlay, f"inference error: {str(e)[:60]}",
                            (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                frame = overlay

            # 4) ë¦¬ì‚¬ì´ì¦ˆ & JPEG ì¸ì½”ë”©
            if scale != 1.0:
                h0, w0 = frame.shape[:2]
                frame = cv2.resize(frame, (int(w0 * scale), int(h0 * scale)), interpolation=cv2.INTER_LINEAR)

            ok, jpg = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)])
            if not ok:
                continue

            yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n"
                   + jpg.tobytes() + b"\r\n")
            del jpg
            time.sleep(0.03)  # ~30fps
    finally:
        try:
            cap.release()
        except Exception:
            pass



# ========= ë¼ìš°íŠ¸ =========
@router.get("/raw")
def stream_raw(
    cam: str = "0",
    scale: float = Query(1.0, ge=0.25, le=2.0),
    quality: int = Query(80, ge=10, le=95),
    roi: int = Query(1, description="ì¢Œì„ ì‹œê°í™”(1=on, 0=off)"),
    w: int = Query(1280),
    h: int = Query(960),
):
    async def _stream():
        try:
            async for chunk in iterate_in_threadpool(
                mjpeg_generator(
                    source=cam,
                    do_blur=False,
                    do_intrusion=False,
                    scale=scale,
                    quality=quality,
                    conf=None,
                    roi_debug=bool(roi),
                    width=w,
                    height=h,
                )
            ):
                yield chunk
        except (GeneratorExit, asyncio.CancelledError):
            # íƒ­ ë‹«í˜ ë“± ì •ìƒ ì¢…ë£Œ
            pass
        except Exception as e:
            print("[stream/raw] outer error:", repr(e))

    return StreamingResponse(_stream(), media_type="multipart/x-mixed-replace; boundary=frame")

@router.get("/blur")
def stream_blur(
    cam: str = "0",
    conf: float | None = Query(None, description="override model confidence (0~1)"),
    scale: float = Query(1.0, ge=0.25, le=2.0),
    quality: int = Query(80, ge=10, le=95),
    roi: int = Query(1, description="ì¢Œì„ ì‹œê°í™”(1=on, 0=off)"),
    w: int = Query(1280, description="ì¶œë ¥ ê°€ë¡œ í•´ìƒë„"),
    h: int = Query(960, description="ì¶œë ¥ ì„¸ë¡œ í•´ìƒë„"),
):
    async def _stream():
        try:
            async for chunk in iterate_in_threadpool(
                mjpeg_generator(
                    source=cam,
                    do_blur=True,
                    do_intrusion=True,
                    scale=scale,
                    quality=quality,
                    conf=conf,
                    roi_debug=bool(roi),
                    width=w,
                    height=h,
                )
            ):
                yield chunk
        except (GeneratorExit, asyncio.CancelledError):
            # íƒ­ ë‹«í˜ ë“± ì •ìƒ ì¢…ë£Œ
            pass
        except Exception as e:
            print("[stream/raw] outer error:", repr(e))

    return StreamingResponse(_stream(), media_type="multipart/x-mixed-replace; boundary=frame")